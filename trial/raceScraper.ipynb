{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import timedelta, date\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "add_link = \"bulli/2033\"\n",
    "race_date = \"11-11-1111\"\n",
    "\n",
    "\n",
    "col = ['date','race_name','race_number','race_place', 'rug', 'dog_name', 'dog_trainer', 'time', 'mgn', 'split', 'inRun', 'wgt', 'sire', 'dam', 'sp']\n",
    "all_data = pd.DataFrame([],columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_scrape():\n",
    "    base_link = \"https://thegreyhoundrecorder.com.au/results/\"\n",
    "\n",
    "    race_name = add_link\n",
    "    link = base_link+add_link\n",
    "    print(link)\n",
    "\n",
    "    raw_html = simple_get(link) #Connection complete\n",
    "    print(len(raw_html))\n",
    "\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "    html_file_name='race.html'\n",
    "    orig_stdout = sys.stdout\n",
    "    f = open(html_file_name, 'w')\n",
    "    sys.stdout = f\n",
    "\n",
    "    print(html.prettify())\n",
    "\n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    raceContent = html.findAll('div',{\"class\": \"resultsDesktopContent tabs\"})[0]\n",
    "\n",
    "    raceTable = raceContent.findAll('table')\n",
    "    no_of_races = int(len(raceTable)/2)\n",
    "    #print(no_of_races)\n",
    "\n",
    "\n",
    "    i=0 # race iterator\n",
    "    while(i<no_of_races):\n",
    "\n",
    "        # ##printing the unique race header\n",
    "\n",
    "        raceHeader = raceTable[2*i]\n",
    "        raceHeader = raceHeader.findAll('td')\n",
    "        #print(len(raceHeader))\n",
    "\n",
    "        raceNumber = raceHeader[0].decode_contents()\n",
    "        raceSubName = raceHeader[1].decode_contents()\n",
    "        raceLength = raceHeader[2].decode_contents()\n",
    "        raceHeaderCategory = raceHeader[3].decode_contents()\n",
    "\n",
    "        raceBets = raceHeader[4].decode_contents()\n",
    "        raceBets = raceBets.replace(' ','')\n",
    "        raceBets = raceBets[:(raceBets.rfind('-')+1)]+raceBets[raceBets.rfind('$'):]\n",
    "\n",
    "        raceSplits = raceHeader[5].decode_contents()\n",
    "        #print(raceNumber+raceSubName+raceLength+raceHeaderCategory+raceBets+raceSplits)\n",
    "\n",
    "        raceBody = raceTable[2*i+1]\n",
    "        raceBody = raceBody.find('tbody')\n",
    "        rows = raceBody.findAll('tr')\n",
    "        no_of_rows = len(rows)\n",
    "\n",
    "        #printing the rest of the table\n",
    "\n",
    "        j = 0 #row iterator\n",
    "        while(j<no_of_rows):\n",
    "            current_row = rows[j].findAll('td')\n",
    "\n",
    "            #print(current_row)\n",
    "\n",
    "            race_place = current_row[0].decode_contents()\n",
    "            rug = current_row[1].decode_contents()\n",
    "            dog_name = current_row[2].find('a')['href'][12:]\n",
    "            dog_trainer = current_row[3].find('a')['href'][10:]\n",
    "            time = current_row[4].decode_contents()\n",
    "            mgn = current_row[5].decode_contents()\n",
    "            split = current_row[6].decode_contents()\n",
    "            inRun = current_row[7].decode_contents()\n",
    "            wgt = current_row[8].decode_contents()\n",
    "            sire = current_row[9].find('a')['href'][12:]\n",
    "            dam = current_row[10].find('a')['href'][12:]\n",
    "            sp = current_row[11].find('p').decode_contents()[2:]\n",
    "\n",
    "            #print(race_place+' '+rug+' '+dog_name+' '+dog_trainer+' '+time+' '+mgn+' '+split+' '+inRun+' '+wgt+' '+sire+' '+dam+' '+sp)\n",
    "\n",
    "            df2 = pd.DataFrame([[race_date, race_name, (i+1), race_place, rug, dog_name, dog_trainer, time, mgn, split, inRun, wgt, sire, dam, sp]],columns=col)\n",
    "            global all_data\n",
    "            all_data = all_data.append(df2)\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, race_name, race_number, race_place, rug, dog_name, dog_trainer, time, mgn, split, inRun, wgt, sire, dam, sp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0\n",
      "0             2016-01-01\n",
      "1             bulli/2033\n",
      "2         cambridge/2035\n",
      "3            darwin/2032\n",
      "4             dubbo/2031\n",
      "5           geelong/2025\n",
      "6           gosford/2027\n",
      "7           ipswich/2029\n",
      "8          mandurah/2034\n",
      "9       strathalbyn/2030\n",
      "10        traralgon/2026\n",
      "11            wagga/2028\n",
      "12            2016-01-02\n",
      "13        addington/2020\n",
      "14        bundaberg/2022\n",
      "15          ipswich/2023\n",
      "16         mandurah/2016\n",
      "17         richmond/2015\n",
      "18         tamworth/2017\n",
      "19      the-gardens/2014\n",
      "20      the-meadows/2012\n",
      "21      warrnambool/2013\n",
      "22         wauchope/2021\n",
      "23   wentworth-park/2018\n",
      "24            young/2019\n",
      "25            2016-01-03\n",
      "26      albion-park/2011\n",
      "27           cairns/2009\n",
      "28           gawler/2010\n",
      "29      healesville/2005\n",
      "..                   ...\n",
      "344         hatrick/1685\n",
      "345         ipswich/1690\n",
      "346        mandurah/1688\n",
      "347            sale/1683\n",
      "348     strathalbyn/1684\n",
      "349     the-gardens/1692\n",
      "350           2016-01-30\n",
      "351        armidale/1674\n",
      "352        ballarat/1669\n",
      "353       bundaberg/1676\n",
      "354         hatrick/1678\n",
      "355         ipswich/1680\n",
      "356         kempsey/1671\n",
      "357        mandurah/1677\n",
      "358        richmond/1679\n",
      "359          temora/1675\n",
      "360     the-gardens/1670\n",
      "361     the-meadows/1668\n",
      "362       traralgon/1667\n",
      "363     tweed-heads/1672\n",
      "364  wentworth-park/1673\n",
      "365           2016-01-31\n",
      "366       addington/1666\n",
      "367     albion-park/1665\n",
      "368        canberra/1663\n",
      "369          gawler/1664\n",
      "370     healesville/1659\n",
      "371   mount-gambier/1662\n",
      "372            sale/1660\n",
      "373    sandown-park/1661\n",
      "\n",
      "[374 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dateFile = pd.read_csv('date.csv')\n",
    "print(dateFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traralgon/2026\n"
     ]
    }
   ],
   "source": [
    "print(dateFile.iloc[10,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01\n",
      "bulli/2033\n",
      "https://thegreyhoundrecorder.com.au/results/bulli/2033\n",
      "291626\n",
      "cambridge/2035\n",
      "https://thegreyhoundrecorder.com.au/results/cambridge/2035\n",
      "327685\n",
      "darwin/2032\n",
      "https://thegreyhoundrecorder.com.au/results/darwin/2032\n",
      "230821\n",
      "dubbo/2031\n",
      "https://thegreyhoundrecorder.com.au/results/dubbo/2031\n",
      "306420\n",
      "geelong/2025\n",
      "https://thegreyhoundrecorder.com.au/results/geelong/2025\n",
      "335506\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-638def6c1b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0madd_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdateFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mrace_scrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f5321a3a8663>\u001b[0m in \u001b[0;36mrace_scrape\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0minRun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mwgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0msire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "t = time.process_time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len_of_date = len(dateFile)\n",
    "k=0\n",
    "while(k<len_of_date):\n",
    "    print(dateFile.iloc[k,0])\n",
    "    if(dateFile.iloc[k,0].find('/')==-1):\n",
    "        race_date = dateFile.iloc[k,0]\n",
    "    else:\n",
    "        add_link = dateFile.iloc[k,0]\n",
    "        race_scrape()\n",
    "    k=k+1\n",
    "    \n",
    "    \n",
    "elapsed_time = time.process_time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('out.csv',index=False)\n",
    "print(type(all_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
